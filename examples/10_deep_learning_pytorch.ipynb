{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# PyTorch Deep Learning Basics\n",
        "\n",
        "This notebook demonstrates fundamental operations with PyTorch.\n",
        "\n",
        "**Libraries:**\n",
        "- [PyTorch](https://pytorch.org/) - Deep learning framework\n",
        "- [TorchVision](https://pytorch.org/vision/) - Computer vision utilities\n",
        "- [TorchAudio](https://pytorch.org/audio/) - Audio processing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchaudio\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TorchAudio version: {torchaudio.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Tensor Basics\n",
        "\n",
        "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with GPU support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check device availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating tensors\n",
        "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
        "y = torch.randn(3, 4)  # Random normal distribution\n",
        "z = torch.zeros(2, 3)\n",
        "ones = torch.ones(2, 2)\n",
        "\n",
        "print(f\"1D Tensor: {x}\")\n",
        "print(f\"Random tensor shape: {y.shape}\")\n",
        "print(f\"Zeros tensor:\\n{z}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tensor operations\n",
        "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "print(f\"Matrix A:\\n{a}\")\n",
        "print(f\"Matrix B:\\n{b}\")\n",
        "print(f\"\\nMatrix multiplication (A @ B):\\n{torch.matmul(a, b)}\")\n",
        "print(f\"\\nElement-wise multiplication (A * B):\\n{a * b}\")\n",
        "print(f\"\\nSum: {a.sum()}\")\n",
        "print(f\"Mean: {a.mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "## Autograd - Automatic Differentiation\n",
        "\n",
        "PyTorch's autograd provides automatic differentiation for all operations on tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tensor with gradient tracking\n",
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "\n",
        "# Forward computation: y = x^2 + 3x + 1\n",
        "y = x ** 2 + 3 * x + 1\n",
        "\n",
        "# Compute gradients\n",
        "y.sum().backward()\n",
        "\n",
        "print(f\"x = {x.data}\")\n",
        "print(f\"y = x^2 + 3x + 1 = {y.data}\")\n",
        "print(f\"dy/dx = 2x + 3 = {x.grad}\")\n",
        "print(f\"\\nVerification: 2*[2,3] + 3 = [{2*2+3}, {2*3+3}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": [
        "## Simple Neural Network\n",
        "\n",
        "Define a neural network using `nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    \"\"\"A simple feedforward neural network.\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "model = SimpleNet(input_size=10, hidden_size=20, output_size=2)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": [
        "## Training Loop Example (XOR Problem)\n",
        "\n",
        "Train a neural network to learn the XOR function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# XOR dataset\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "print(\"XOR Truth Table:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"  {int(X[i][0])} XOR {int(X[i][1])} = {int(y[i][0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple network for XOR\n",
        "class XORNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)\n",
        "        self.fc2 = nn.Linear(4, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "xor_model = XORNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(xor_model.parameters(), lr=0.1)\n",
        "\n",
        "print(\"XOR Network:\")\n",
        "print(xor_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "print(\"Training XOR classifier...\")\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1000):\n",
        "    # Forward pass\n",
        "    outputs = xor_model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test predictions\n",
        "with torch.no_grad():\n",
        "    predictions = xor_model(X)\n",
        "    print(\"Predictions after training:\")\n",
        "    for i in range(len(X)):\n",
        "        pred = predictions[i].item()\n",
        "        expected = y[i].item()\n",
        "        print(f\"  {X[i].tolist()} -> {pred:.4f} (expected: {expected})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## TorchVision Transforms\n",
        "\n",
        "Image preprocessing pipelines for computer vision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a transform pipeline for image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "print(\"Transform pipeline for image preprocessing:\")\n",
        "print(\"  1. Resize to 224x224\")\n",
        "print(\"  2. Convert to tensor (HWC -> CHW, scale to [0,1])\")\n",
        "print(\"  3. Normalize with ImageNet statistics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation transforms\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "print(\"Data augmentation transforms:\")\n",
        "print(\"  - Random horizontal flip\")\n",
        "print(\"  - Random rotation (+/- 15 degrees)\")\n",
        "print(\"  - Color jitter\")\n",
        "print(\"  - Random resized crop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "## TorchAudio Basics\n",
        "\n",
        "Audio processing with TorchAudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a synthetic waveform (A4 note = 440 Hz)\n",
        "sample_rate = 16000\n",
        "duration = 1.0  # seconds\n",
        "t = torch.linspace(0, duration, int(sample_rate * duration))\n",
        "frequency = 440  # Hz (A4 note)\n",
        "waveform = torch.sin(2 * torch.pi * frequency * t).unsqueeze(0)\n",
        "\n",
        "print(\"Synthetic waveform created:\")\n",
        "print(f\"  Sample rate: {sample_rate} Hz\")\n",
        "print(f\"  Duration: {duration} seconds\")\n",
        "print(f\"  Frequency: {frequency} Hz (A4 note)\")\n",
        "print(f\"  Shape: {waveform.shape} (channels, samples)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply Mel Spectrogram transform\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=sample_rate,\n",
        "    n_mels=64,\n",
        ")\n",
        "mel_spec = mel_spectrogram(waveform)\n",
        "\n",
        "print(f\"Mel spectrogram shape: {mel_spec.shape}\")\n",
        "print(f\"  - Channels: {mel_spec.shape[0]}\")\n",
        "print(f\"  - Mel bins: {mel_spec.shape[1]}\")\n",
        "print(f\"  - Time frames: {mel_spec.shape[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Other audio transforms\n",
        "mfcc_transform = torchaudio.transforms.MFCC(\n",
        "    sample_rate=sample_rate,\n",
        "    n_mfcc=13,\n",
        ")\n",
        "mfcc = mfcc_transform(waveform)\n",
        "print(f\"MFCC shape: {mfcc.shape}\")\n",
        "\n",
        "# Spectrogram\n",
        "spec_transform = torchaudio.transforms.Spectrogram()\n",
        "spec = spec_transform(waveform)\n",
        "print(f\"Spectrogram shape: {spec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Tensor Basics**: Creating tensors, operations, device management\n",
        "2. **Autograd**: Automatic differentiation with `requires_grad`\n",
        "3. **Neural Networks**: Defining models with `nn.Module`\n",
        "4. **Training Loop**: Forward pass, loss, backward pass, optimizer step\n",
        "5. **TorchVision**: Image transforms and augmentation\n",
        "6. **TorchAudio**: Audio waveforms, Mel spectrograms, MFCCs\n",
        "\n",
        "For more information:\n",
        "- [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
        "- [TorchVision Documentation](https://pytorch.org/vision/stable/)\n",
        "- [TorchAudio Documentation](https://pytorch.org/audio/stable/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
