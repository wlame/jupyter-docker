{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Machine Learning Examples\n",
        "\n",
        "This notebook demonstrates machine learning with scikit-learn, XGBoost, and LightGBM.\n",
        "\n",
        "**Libraries:**\n",
        "- [scikit-learn](https://scikit-learn.org/) - Machine learning in Python\n",
        "- [XGBoost](https://xgboost.readthedocs.io/) - Gradient boosting framework\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/) - Light Gradient Boosting Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.datasets import make_classification, make_regression, load_iris\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    roc_curve,\n",
        "    auc,\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Gradient boosting libraries\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Classification with Multiple Models\n",
        "\n",
        "Compare different classifiers on a synthetic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=15,\n",
        "    n_redundant=5,\n",
        "    n_classes=2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric=\"logloss\"),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
        "}\n",
        "\n",
        "# Train and evaluate\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    # Create pipeline with scaling\n",
        "    pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
        "    \n",
        "    # Fit\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    \n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
        "    \n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"CV Mean\": cv_scores.mean(),\n",
        "        \"CV Std\": cv_scores.std(),\n",
        "    })\n",
        "    \n",
        "    print(f\"{name}: Accuracy={accuracy:.4f}, CV={cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results comparison\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(\"CV Mean\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "## Detailed Classification Report\n",
        "\n",
        "In-depth analysis of XGBoost model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric=\"logloss\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "y_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC Curve and Feature Importance\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# ROC Curve\n",
        "axes[0].plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "axes[0].plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "axes[0].set_xlabel(\"False Positive Rate\")\n",
        "axes[0].set_ylabel(\"True Positive Rate\")\n",
        "axes[0].set_title(\"ROC Curve\")\n",
        "axes[0].legend(loc=\"lower right\")\n",
        "\n",
        "# Feature Importance\n",
        "importance = pd.Series(xgb_model.feature_importances_).sort_values(ascending=True)\n",
        "importance.tail(10).plot(kind=\"barh\", ax=axes[1])\n",
        "axes[1].set_title(\"Top 10 Feature Importances\")\n",
        "axes[1].set_xlabel(\"Importance\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## Regression Example\n",
        "\n",
        "Compare regression models on a synthetic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate regression dataset\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=1000, n_features=10, n_informative=8, noise=20, random_state=42\n",
        ")\n",
        "\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train_r.shape}\")\n",
        "print(f\"Test set: {X_test_r.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train regression models\n",
        "reg_models = {\n",
        "    \"Ridge\": Ridge(alpha=1.0),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1),\n",
        "}\n",
        "\n",
        "reg_results = []\n",
        "for name, model in reg_models.items():\n",
        "    model.fit(X_train_r, y_train_r)\n",
        "    y_pred_r = model.predict(X_test_r)\n",
        "    \n",
        "    mse = mean_squared_error(y_test_r, y_pred_r)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test_r, y_pred_r)\n",
        "    \n",
        "    reg_results.append({\"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
        "    print(f\"{name}: RMSE={rmse:.2f}, R2={r2:.4f}\")\n",
        "\n",
        "pd.DataFrame(reg_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning with GridSearchCV\n",
        "\n",
        "Find optimal hyperparameters using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100],\n",
        "    \"max_depth\": [5, 10, None],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring=\"accuracy\", n_jobs=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
        "print(f\"Test accuracy: {grid_search.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {},
      "source": [
        "## Clustering with K-Means\n",
        "\n",
        "Unsupervised learning example using the Iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_iris)\n",
        "\n",
        "# K-Means clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "print(f\"Cluster sizes: {np.bincount(clusters)}\")\n",
        "print(f\"Inertia: {kmeans.inertia_:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot comparison: True labels vs K-Means clusters\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# True labels\n",
        "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=iris.target, cmap=\"viridis\")\n",
        "axes[0].set_title(\"True Labels\")\n",
        "axes[0].set_xlabel(\"PC1\")\n",
        "axes[0].set_ylabel(\"PC2\")\n",
        "\n",
        "# Predicted clusters\n",
        "scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap=\"viridis\")\n",
        "centers = pca.transform(kmeans.cluster_centers_)\n",
        "axes[1].scatter(centers[:, 0], centers[:, 1], c=\"red\", marker=\"x\", s=200, linewidths=3, label=\"Centroids\")\n",
        "axes[1].set_title(\"K-Means Clusters\")\n",
        "axes[1].set_xlabel(\"PC1\")\n",
        "axes[1].set_ylabel(\"PC2\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "## Dimensionality Reduction with PCA\n",
        "\n",
        "Analyze variance explained by principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full PCA analysis\n",
        "pca_full = PCA()\n",
        "pca_full.fit(X_scaled)\n",
        "\n",
        "# Cumulative explained variance\n",
        "cumvar = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Explained variance per component\n",
        "axes[0].bar(range(1, len(pca_full.explained_variance_ratio_) + 1), \n",
        "            pca_full.explained_variance_ratio_)\n",
        "axes[0].set_xlabel(\"Principal Component\")\n",
        "axes[0].set_ylabel(\"Explained Variance Ratio\")\n",
        "axes[0].set_title(\"Variance Explained by Each Component\")\n",
        "\n",
        "# Cumulative variance\n",
        "axes[1].plot(range(1, len(cumvar) + 1), cumvar, \"bo-\")\n",
        "axes[1].axhline(y=0.95, color=\"r\", linestyle=\"--\", label=\"95% variance\")\n",
        "axes[1].set_xlabel(\"Number of Components\")\n",
        "axes[1].set_ylabel(\"Cumulative Explained Variance\")\n",
        "axes[1].set_title(\"Cumulative Variance Explained\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find number of components for 95% variance\n",
        "n_components_95 = np.argmax(cumvar >= 0.95) + 1\n",
        "print(f\"Components needed for 95% variance: {n_components_95}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Classification**: Comparing Logistic Regression, Random Forest, Gradient Boosting, XGBoost, LightGBM\n",
        "2. **Model Evaluation**: Classification report, confusion matrix, ROC curve, AUC\n",
        "3. **Regression**: Ridge, Random Forest, XGBoost, LightGBM with RMSE and R2 metrics\n",
        "4. **Hyperparameter Tuning**: GridSearchCV for finding optimal parameters\n",
        "5. **Clustering**: K-Means with visualization\n",
        "6. **Dimensionality Reduction**: PCA and variance analysis\n",
        "\n",
        "For more information:\n",
        "- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)\n",
        "- [XGBoost Documentation](https://xgboost.readthedocs.io/)\n",
        "- [LightGBM Documentation](https://lightgbm.readthedocs.io/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
