{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Data Analysis\n",
    "\n",
    "This notebook demonstrates data manipulation and analysis with Pandas.\n",
    "\n",
    "**Library:** [Pandas](https://pandas.pydata.org/) - Data manipulation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "\n",
    "A DataFrame is the primary data structure in Pandas - a 2D labeled data structure with columns of potentially different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from dictionary\n",
    "data = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 28, 32],\n",
    "    \"department\": [\"Engineering\", \"Marketing\", \"Engineering\", \"Sales\", \"Marketing\"],\n",
    "    \"salary\": [75000, 65000, 85000, 70000, 72000],\n",
    "    \"start_date\": pd.date_range(\"2020-01-01\", periods=5, freq=\"3ME\"),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection and Filtering\n",
    "\n",
    "Pandas provides powerful ways to select and filter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single column\n",
    "df[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "df[[\"name\", \"department\", \"salary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by condition\n",
    "engineers = df[df[\"department\"] == \"Engineering\"]\n",
    "print(\"Engineers only:\")\n",
    "engineers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions with & (and) and | (or)\n",
    "high_earners = df[(df[\"salary\"] > 70000) & (df[\"age\"] < 35)]\n",
    "print(\"High earners under 35:\")\n",
    "high_earners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using query() for more readable filtering\n",
    "result = df.query(\"department == 'Marketing' and salary > 60000\")\n",
    "print(\"Marketing with salary > 60000:\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation and Grouping\n",
    "\n",
    "Pandas makes it easy to compute summary statistics and group data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives summary statistics\n",
    "df[\"salary\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by department and aggregate\n",
    "dept_stats = df.groupby(\"department\").agg(\n",
    "    {\"salary\": [\"mean\", \"min\", \"max\", \"count\"], \"age\": \"mean\"}\n",
    ")\n",
    "print(\"Statistics by department:\")\n",
    "dept_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation with apply\n",
    "summary = df.groupby(\"department\").apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\"avg_salary\": x[\"salary\"].mean(), \"total_employees\": len(x)}\n",
    "    )\n",
    ")\n",
    "print(\"Custom summary by department:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "Adding new columns and transforming existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add categorical column based on salary\n",
    "df[\"salary_category\"] = pd.cut(\n",
    "    df[\"salary\"], bins=[0, 70000, 80000, float(\"inf\")], labels=[\"Low\", \"Medium\", \"High\"]\n",
    ")\n",
    "\n",
    "# Calculate years employed\n",
    "df[\"years_employed\"] = (datetime.now() - df[\"start_date\"]).dt.days / 365\n",
    "\n",
    "print(\"DataFrame with new columns:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize salary within each department using transform\n",
    "df[\"salary_normalized\"] = df.groupby(\"department\")[\"salary\"].transform(\n",
    "    lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0\n",
    ")\n",
    "df[[\"name\", \"department\", \"salary\", \"salary_normalized\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "\n",
    "Pivot tables allow you to reshape data and compute aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "sales_data = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": pd.date_range(\"2024-01-01\", periods=12, freq=\"ME\"),\n",
    "        \"region\": [\"North\", \"South\"] * 6,\n",
    "        \"product\": [\"A\", \"B\", \"A\", \"B\"] * 3,\n",
    "        \"sales\": np.random.randint(1000, 5000, 12),\n",
    "    }\n",
    ")\n",
    "print(\"Sales data:\")\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table\n",
    "pivot = pd.pivot_table(\n",
    "    sales_data, values=\"sales\", index=\"region\", columns=\"product\", aggfunc=\"sum\"\n",
    ")\n",
    "print(\"Sales pivot table (sum by region and product):\")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Operations\n",
    "\n",
    "Pandas has excellent support for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series with datetime index\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(\"2024-01-01\", periods=100, freq=\"D\")\n",
    "ts = pd.Series(np.random.randn(100).cumsum(), index=dates)\n",
    "\n",
    "print(\"Time series (first 10 days):\")\n",
    "ts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Change the frequency of your time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to weekly frequency\n",
    "weekly = ts.resample(\"W\").mean()\n",
    "print(\"Weekly resampled (mean):\")\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Statistics\n",
    "\n",
    "Compute statistics over a sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day rolling mean\n",
    "rolling = ts.rolling(window=7).mean()\n",
    "print(\"7-day rolling mean (last 10 values):\")\n",
    "rolling.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Handling missing values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create messy data with missing values\n",
    "messy = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1, 2, np.nan, 4, 5],\n",
    "        \"B\": [np.nan, 2, 3, np.nan, 5],\n",
    "        \"C\": [\"x\", \"y\", \"z\", \"x\", \"y\"],\n",
    "    }\n",
    ")\n",
    "print(\"Messy data:\")\n",
    "messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "messy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "filled = messy.fillna({\"A\": messy[\"A\"].mean(), \"B\": 0})\n",
    "print(\"Filled data:\")\n",
    "filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with duplicates\n",
    "with_dups = pd.DataFrame({\"x\": [1, 1, 2], \"y\": [1, 1, 3]})\n",
    "print(\"With duplicates:\")\n",
    "print(with_dups)\n",
    "\n",
    "print(\"\\nWithout duplicates:\")\n",
    "with_dups.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Creating DataFrames** from dictionaries and other sources\n",
    "2. **Selection and Filtering** using conditions and query()\n",
    "3. **Aggregation and Grouping** with groupby() and agg()\n",
    "4. **Data Transformation** adding columns and applying functions\n",
    "5. **Pivot Tables** for reshaping data\n",
    "6. **Time Series Operations** including resampling and rolling statistics\n",
    "7. **Data Cleaning** handling missing values and duplicates\n",
    "\n",
    "For more information, visit the [Pandas Documentation](https://pandas.pydata.org/docs/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
