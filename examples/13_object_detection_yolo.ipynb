{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Object Detection with Ultralytics YOLO\n",
        "\n",
        "This notebook demonstrates object detection using Ultralytics YOLOv8.\n",
        "\n",
        "**Library:** [Ultralytics](https://ultralytics.com/) - State-of-the-art YOLO implementation\n",
        "\n",
        "YOLO (You Only Look Once) is a real-time object detection system that can detect multiple objects in a single forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## YOLO Model Overview\n",
        "\n",
        "Available YOLOv8 model sizes (speed vs accuracy trade-off):\n",
        "\n",
        "| Model | Size | Speed | Accuracy |\n",
        "|-------|------|-------|----------|\n",
        "| yolov8n | Nano | Fastest | Lower |\n",
        "| yolov8s | Small | Fast | Good |\n",
        "| yolov8m | Medium | Balanced | Better |\n",
        "| yolov8l | Large | Slower | High |\n",
        "| yolov8x | XLarge | Slowest | Highest |\n",
        "\n",
        "Task-specific models:\n",
        "- Detection: `yolov8n.pt`\n",
        "- Segmentation: `yolov8n-seg.pt`\n",
        "- Classification: `yolov8n-cls.pt`\n",
        "- Pose Estimation: `yolov8n-pose.pt`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Create Sample Image\n",
        "\n",
        "Create a sample scene with drawable objects for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample scene image\n",
        "width, height = 640, 480\n",
        "sample_image = Image.new(\"RGB\", (width, height), color=(135, 206, 235))  # Sky blue\n",
        "draw = ImageDraw.Draw(sample_image)\n",
        "\n",
        "# Draw ground\n",
        "draw.rectangle([0, int(height * 0.7), width, height], fill=(34, 139, 34))  # Green grass\n",
        "\n",
        "# Draw a simple \"car\"\n",
        "car_x, car_y = 100, 300\n",
        "draw.rectangle([car_x, car_y, car_x + 150, car_y + 60], fill=(255, 0, 0))  # Body\n",
        "draw.rectangle([car_x + 20, car_y - 30, car_x + 130, car_y], fill=(255, 0, 0))  # Top\n",
        "draw.ellipse([car_x + 20, car_y + 40, car_x + 50, car_y + 70], fill=(30, 30, 30))  # Wheel\n",
        "draw.ellipse([car_x + 100, car_y + 40, car_x + 130, car_y + 70], fill=(30, 30, 30))  # Wheel\n",
        "\n",
        "# Draw a simple \"person\"\n",
        "person_x, person_y = 400, 280\n",
        "draw.ellipse([person_x - 15, person_y - 50, person_x + 15, person_y - 20], fill=(255, 218, 185))  # Head\n",
        "draw.rectangle([person_x - 20, person_y - 20, person_x + 20, person_y + 50], fill=(0, 0, 255))  # Body\n",
        "draw.rectangle([person_x - 10, person_y + 50, person_x + 10, person_y + 100], fill=(0, 0, 139))  # Legs\n",
        "\n",
        "# Draw sun\n",
        "draw.ellipse([width - 100, 30, width - 30, 100], fill=(255, 255, 0))\n",
        "\n",
        "# Draw clouds\n",
        "for cx, cy in [(150, 60), (180, 50), (210, 60), (180, 70)]:\n",
        "    draw.ellipse([cx - 25, cy - 20, cx + 25, cy + 20], fill=(255, 255, 255))\n",
        "\n",
        "print(f\"Sample scene created: {sample_image.size}\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(sample_image)\n",
        "plt.title(\"Sample Scene\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "## Load YOLO Model\n",
        "\n",
        "Load a pretrained YOLOv8 model. The model will be downloaded automatically on first use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained YOLOv8 nano model (smallest, fastest)\n",
        "print(\"Loading YOLOv8n model...\")\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Model type: {type(model).__name__}\")\n",
        "print(f\"Task: {model.task}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## Model Information\n",
        "\n",
        "Explore the model's class names and capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get class names the model can detect\n",
        "class_names = model.names\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"\\nSample classes (first 20):\")\n",
        "for i, name in list(class_names.items())[:20]:\n",
        "    print(f\"  {i}: {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "## Run Inference\n",
        "\n",
        "Run object detection on our sample image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference on the sample image\n",
        "img_array = np.array(sample_image)\n",
        "results = model(img_array, verbose=False)\n",
        "\n",
        "# Get the first result\n",
        "result = results[0]\n",
        "print(f\"Image shape: {result.orig_shape}\")\n",
        "print(f\"Inference speed: {result.speed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze detections\n",
        "boxes = result.boxes\n",
        "print(f\"\\nDetections found: {len(boxes)}\")\n",
        "\n",
        "if len(boxes) > 0:\n",
        "    print(\"\\nDetected objects:\")\n",
        "    for i, box in enumerate(boxes):\n",
        "        cls_id = int(box.cls[0])\n",
        "        cls_name = class_names[cls_id]\n",
        "        conf = float(box.conf[0])\n",
        "        xyxy = box.xyxy[0].tolist()\n",
        "        print(f\"  {i+1}. {cls_name}: confidence={conf:.2f}, box={[int(x) for x in xyxy]}\")\n",
        "else:\n",
        "    print(\"\\nNo objects detected in the simple drawn image.\")\n",
        "    print(\"(YOLO is trained on real photos, not simple drawings)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display annotated image\n",
        "annotated_img = result.plot()  # Returns numpy array with annotations\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(annotated_img)\n",
        "plt.title(\"YOLO Detection Results\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## Using YOLO with NumPy Arrays\n",
        "\n",
        "YOLO accepts various input formats including file paths, numpy arrays, PIL images, and lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different input formats\n",
        "print(\"YOLO accepts multiple input formats:\")\n",
        "print(\"  - File path: model('image.jpg')\")\n",
        "print(\"  - PIL Image: model(pil_image)\")\n",
        "print(\"  - NumPy array: model(numpy_array)\")\n",
        "print(\"  - List of images: model([img1, img2, img3])\")\n",
        "print(\"  - URL: model('https://example.com/image.jpg')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference on numpy array\n",
        "print(f\"Input array shape: {img_array.shape}\")\n",
        "results_np = model(img_array, verbose=False)\n",
        "print(f\"Detections: {len(results_np[0].boxes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## Batch Processing\n",
        "\n",
        "Process multiple images in a single batch for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create multiple images for batch processing\n",
        "batch_images = []\n",
        "for i in range(3):\n",
        "    img = sample_image.copy()\n",
        "    d = ImageDraw.Draw(img)\n",
        "    # Add unique marker to each\n",
        "    d.rectangle([10, 10, 50, 50], fill=(i * 80, 100, 200))\n",
        "    batch_images.append(np.array(img))\n",
        "\n",
        "# Run batch inference\n",
        "batch_results = model(batch_images, verbose=False)\n",
        "\n",
        "print(f\"Processed {len(batch_results)} images in batch\")\n",
        "for i, res in enumerate(batch_results):\n",
        "    print(f\"  Image {i+1}: {len(res.boxes)} detections\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {},
      "source": [
        "## Model Export Options\n",
        "\n",
        "YOLO models can be exported to various formats for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"YOLO models can be exported to various formats:\")\n",
        "print(\"\")\n",
        "print(\"  model.export(format='onnx')        # ONNX format\")\n",
        "print(\"  model.export(format='torchscript') # TorchScript\")\n",
        "print(\"  model.export(format='tflite')      # TensorFlow Lite\")\n",
        "print(\"  model.export(format='coreml')      # CoreML (iOS)\")\n",
        "print(\"  model.export(format='engine')      # TensorRT\")\n",
        "print(\"\")\n",
        "print(\"Supported formats:\")\n",
        "print(\"  PyTorch, TorchScript, ONNX, OpenVINO, TensorRT,\")\n",
        "print(\"  CoreML, TF SavedModel, TF GraphDef, TF Lite,\")\n",
        "print(\"  TF Edge TPU, TF.js, PaddlePaddle, ncnn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-20",
      "metadata": {},
      "source": [
        "## Training Custom Models\n",
        "\n",
        "How to train YOLO on your own dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"To train YOLO on custom data:\")\n",
        "print(\"\")\n",
        "print(\"1. Prepare dataset in YOLO format:\")\n",
        "print(\"   dataset/\")\n",
        "print(\"   ├── train/\")\n",
        "print(\"   │   ├── images/\")\n",
        "print(\"   │   └── labels/\")\n",
        "print(\"   └── val/\")\n",
        "print(\"       ├── images/\")\n",
        "print(\"       └── labels/\")\n",
        "print(\"\")\n",
        "print(\"2. Create data.yaml:\")\n",
        "print(\"   train: path/to/train/images\")\n",
        "print(\"   val: path/to/val/images\")\n",
        "print(\"   nc: 2  # number of classes\")\n",
        "print(\"   names: ['class1', 'class2']\")\n",
        "print(\"\")\n",
        "print(\"3. Train:\")\n",
        "print(\"   model = YOLO('yolov8n.pt')\")\n",
        "print(\"   model.train(data='data.yaml', epochs=100, imgsz=640)\")\n",
        "print(\"\")\n",
        "print(\"4. Validate:\")\n",
        "print(\"   metrics = model.val()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-22",
      "metadata": {},
      "source": [
        "## YOLO Tasks\n",
        "\n",
        "Different YOLO tasks available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-23",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"YOLO Task Examples:\")\n",
        "print(\"\")\n",
        "print(\"Detection (default):\")\n",
        "print(\"  model = YOLO('yolov8n.pt')\")\n",
        "print(\"  results = model('image.jpg')\")\n",
        "print(\"  boxes = results[0].boxes  # Bounding boxes\")\n",
        "print(\"\")\n",
        "print(\"Segmentation:\")\n",
        "print(\"  model = YOLO('yolov8n-seg.pt')\")\n",
        "print(\"  results = model('image.jpg')\")\n",
        "print(\"  masks = results[0].masks  # Instance segmentation masks\")\n",
        "print(\"\")\n",
        "print(\"Classification:\")\n",
        "print(\"  model = YOLO('yolov8n-cls.pt')\")\n",
        "print(\"  results = model('image.jpg')\")\n",
        "print(\"  probs = results[0].probs  # Classification probabilities\")\n",
        "print(\"\")\n",
        "print(\"Pose Estimation:\")\n",
        "print(\"  model = YOLO('yolov8n-pose.pt')\")\n",
        "print(\"  results = model('image.jpg')\")\n",
        "print(\"  keypoints = results[0].keypoints  # Body keypoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-24",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **YOLO Overview**: Model sizes (nano to xlarge), task-specific models\n",
        "2. **Loading Models**: Automatic download of pretrained weights\n",
        "3. **Running Inference**: On images, numpy arrays, batches\n",
        "4. **Analyzing Results**: Boxes, classes, confidence scores\n",
        "5. **Export Options**: ONNX, TensorRT, CoreML, TFLite, etc.\n",
        "6. **Training**: Custom dataset format and training workflow\n",
        "7. **Tasks**: Detection, Segmentation, Classification, Pose\n",
        "\n",
        "For more information:\n",
        "- [Ultralytics Documentation](https://docs.ultralytics.com/)\n",
        "- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)\n",
        "- [YOLO Training Guide](https://docs.ultralytics.com/modes/train/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
