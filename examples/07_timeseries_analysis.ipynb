{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "This notebook demonstrates time series analysis techniques.\n",
    "\n",
    "**Libraries:**\n",
    "- [statsmodels](https://www.statsmodels.org/) - Statistical models\n",
    "- [pmdarima](https://alkaline-ml.com/pmdarima/) - Auto-ARIMA\n",
    "- [tsfresh](https://tsfresh.readthedocs.io/) - Feature extraction\n",
    "- [sktime](https://www.sktime.net/) - Time series ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create time series with trend, seasonality, and noise\n",
    "n_periods = 365 * 2  # 2 years of daily data\n",
    "dates = pd.date_range(\"2023-01-01\", periods=n_periods, freq=\"D\")\n",
    "\n",
    "# Components\n",
    "trend = np.linspace(100, 150, n_periods)\n",
    "seasonal = 20 * np.sin(2 * np.pi * np.arange(n_periods) / 365)  # Yearly\n",
    "weekly = 5 * np.sin(2 * np.pi * np.arange(n_periods) / 7)  # Weekly\n",
    "noise = np.random.randn(n_periods) * 5\n",
    "\n",
    "ts = pd.Series(trend + seasonal + weekly + noise, index=dates, name=\"value\")\n",
    "\n",
    "print(f\"Time series shape: {ts.shape}\")\n",
    "print(f\"Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "ts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ts.plot(ax=ax)\n",
    "ax.set_title(\"Sample Time Series (Trend + Seasonality + Noise)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Decomposition\n",
    "\n",
    "Decompose the series into trend, seasonal, and residual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(ts, model=\"additive\", period=365)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "decomposition.observed.plot(ax=axes[0], title=\"Observed\")\n",
    "decomposition.trend.plot(ax=axes[1], title=\"Trend\")\n",
    "decomposition.seasonal.plot(ax=axes[2], title=\"Seasonal\")\n",
    "decomposition.resid.plot(ax=axes[3], title=\"Residual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests for Stationarity\n",
    "\n",
    "### Augmented Dickey-Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(ts.dropna())\n",
    "\n",
    "print(\"Augmented Dickey-Fuller Test:\")\n",
    "print(f\"  Test Statistic: {result[0]:.4f}\")\n",
    "print(f\"  p-value: {result[1]:.4f}\")\n",
    "print(f\"  Lags Used: {result[2]}\")\n",
    "print(\"  Critical Values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"    {key}: {value:.4f}\")\n",
    "\n",
    "conclusion = \"stationary (reject null)\" if result[1] < 0.05 else \"non-stationary (fail to reject)\"\n",
    "print(f\"\\n  -> Series is {conclusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# ACF\n",
    "acf_values = acf(ts, nlags=40)\n",
    "axes[0].bar(range(len(acf_values)), acf_values)\n",
    "axes[0].axhline(y=0, linestyle=\"-\", color=\"black\")\n",
    "axes[0].axhline(y=1.96/np.sqrt(len(ts)), linestyle=\"--\", color=\"gray\")\n",
    "axes[0].axhline(y=-1.96/np.sqrt(len(ts)), linestyle=\"--\", color=\"gray\")\n",
    "axes[0].set_title(\"Autocorrelation Function (ACF)\")\n",
    "axes[0].set_xlabel(\"Lag\")\n",
    "\n",
    "# PACF\n",
    "pacf_values = pacf(ts, nlags=40)\n",
    "axes[1].bar(range(len(pacf_values)), pacf_values)\n",
    "axes[1].axhline(y=0, linestyle=\"-\", color=\"black\")\n",
    "axes[1].axhline(y=1.96/np.sqrt(len(ts)), linestyle=\"--\", color=\"gray\")\n",
    "axes[1].axhline(y=-1.96/np.sqrt(len(ts)), linestyle=\"--\", color=\"gray\")\n",
    "axes[1].set_title(\"Partial Autocorrelation Function (PACF)\")\n",
    "axes[1].set_xlabel(\"Lag\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use monthly data for faster computation\n",
    "monthly_ts = ts.resample(\"ME\").mean()\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(monthly_ts) * 0.8)\n",
    "train, test = monthly_ts[:train_size], monthly_ts[train_size:]\n",
    "\n",
    "print(f\"Training: {len(train)} months\")\n",
    "print(f\"Testing: {len(test)} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "model = ARIMA(train, order=(1, 1, 1))\n",
    "fitted = model.fit()\n",
    "\n",
    "print(\"ARIMA(1,1,1) Model:\")\n",
    "print(f\"  AIC: {fitted.aic:.2f}\")\n",
    "print(f\"  BIC: {fitted.bic:.2f}\")\n",
    "\n",
    "# Forecast\n",
    "forecast = fitted.forecast(steps=len(test))\n",
    "mape = np.mean(np.abs((test - forecast) / test)) * 100\n",
    "print(f\"  Forecast MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "train.plot(ax=ax, label=\"Training Data\")\n",
    "test.plot(ax=ax, label=\"Test Data\")\n",
    "forecast.plot(ax=ax, label=\"Forecast\", linestyle=\"--\")\n",
    "ax.set_title(\"ARIMA Forecast\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-ARIMA with pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = pm.auto_arima(\n",
    "    train,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=3, max_q=3,\n",
    "    seasonal=False,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest model: ARIMA{auto_model.order}\")\n",
    "print(f\"AIC: {auto_model.aic():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tsfresh - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for tsfresh\n",
    "tsfresh_data = []\n",
    "for series_id in range(5):\n",
    "    for t, val in enumerate(ts.values[:100]):\n",
    "        tsfresh_data.append({\"id\": series_id, \"time\": t, \"value\": val + np.random.randn() * 10})\n",
    "\n",
    "tsfresh_df = pd.DataFrame(tsfresh_data)\n",
    "print(f\"tsfresh input shape: {tsfresh_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features = extract_features(\n",
    "    tsfresh_df,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_value=\"value\",\n",
    "    default_fc_parameters=MinimalFCParameters(),\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "print(f\"Extracted {features.shape[1]} features for {features.shape[0]} time series\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sktime Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for sktime\n",
    "y = monthly_ts.copy()\n",
    "y.index = pd.PeriodIndex(y.index, freq=\"M\")\n",
    "\n",
    "# Split\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=0.2)\n",
    "\n",
    "# Naive forecaster\n",
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh=list(range(1, len(y_test) + 1)))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"Naive Forecaster MAPE: {mape * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 30\n",
    "rolling_mean = ts.rolling(window=window).mean()\n",
    "rolling_std = ts.rolling(window=window).std()\n",
    "\n",
    "# Z-score anomaly detection\n",
    "z_scores = (ts - rolling_mean) / rolling_std\n",
    "anomalies = ts[np.abs(z_scores) > 3]\n",
    "\n",
    "print(f\"Detected {len(anomalies)} anomalies (|z-score| > 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(ts.index, ts.values, alpha=0.5, label=\"Original\")\n",
    "axes[0].plot(rolling_mean.index, rolling_mean.values, label=\"30-day MA\")\n",
    "axes[0].fill_between(rolling_mean.index, rolling_mean - 2*rolling_std,\n",
    "                     rolling_mean + 2*rolling_std, alpha=0.2, label=\"2 Std Dev\")\n",
    "axes[0].scatter(anomalies.index, anomalies.values, color=\"red\", s=50, label=\"Anomalies\")\n",
    "axes[0].set_title(\"Time Series with Anomalies\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(z_scores.index, z_scores.values)\n",
    "axes[1].axhline(y=3, color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
    "axes[1].axhline(y=-3, color=\"red\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Z-Scores\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Time Series Decomposition**: Trend, seasonal, and residual components\n",
    "2. **Statistical Tests**: ADF test, ACF, PACF\n",
    "3. **ARIMA Modeling**: Manual and auto-ARIMA\n",
    "4. **Feature Extraction**: tsfresh for automated feature generation\n",
    "5. **Forecasting**: sktime naive forecaster\n",
    "6. **Anomaly Detection**: Z-score based detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
